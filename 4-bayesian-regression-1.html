<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="4 Bayesian regression | Bayesian Regression" />
<meta property="og:type" content="book" />





<meta name="author" content="Cory Whitney" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="4 Bayesian regression | Bayesian Regression">

<title>4 Bayesian regression | Bayesian Regression</title>

<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/united.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="libs/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="1-bayesian-regression.html#bayesian-regression"><span class="toc-section-number">1</span> Bayesian regression</a></li>
<li><a href="2-data-preparation.html#data-preparation"><span class="toc-section-number">2</span> Data preparation</a></li>
<li><a href="3-classical-linear-regression-model.html#classical-linear-regression-model"><span class="toc-section-number">3</span> Classical linear regression model</a></li>
<li><a href="4-bayesian-regression-1.html#bayesian-regression-1"><span class="toc-section-number">4</span> Bayesian regression</a></li>
<li><a href="5-bayesian-inferences.html#bayesian-inferences"><span class="toc-section-number">5</span> Bayesian inferences</a></li>
<li><a href="6-pd-and-p-value.html#pd-and-p-value"><span class="toc-section-number">6</span> PD and P-value</a></li>
<li><a href="7-credit.html#credit"><span class="toc-section-number">7</span> credit</a></li>
<li><a href="8-references.html#references"><span class="toc-section-number">8</span> References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="bayesian-regression-1" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Bayesian regression</h1>
<p>To fit a Bayesian regresion we use the function <code>stan_glm</code> from the <code>rstanarm</code> package. This function as the above <code>lm</code> function requires providing the formula and the data that will be used. The other arguments are:</p>
<p><code>family</code>: by default this function uses the gaussian distribution as we do with the classical glm function to perform <code>lm</code> model.</p>
<p><code>prior</code>: The prior distribution for the regression coefficients, By default the normal prior is used, set this to NULL for a flat uniform prior. For other prior options in <code>rstanarm</code>, see <code>?priors</code>.</p>
<p><code>prior_intercept</code>: prior for the intercept, can be normal, student_t , or cauchy. If we want a flat uniform prior we set this to NULL.</p>
<p><code>prior_aux</code>: prior fo auxiliary parameters such as the error standard deviation for the gaussion family.
algorithm: The estimating approach to use. The default is "sampling MCMC1.</p>
<p><code>QR</code>: FALSE by default, if true QR decomposition applied on the design matrix if we have large number of predictors.
iter : is the number of iterations if the MCMC method is used, the default is 2000.</p>
<p><code>chains</code>: the number of Markov chains, the default is 4.</p>
<p><code>warmup</code>: also known as ‘burnin’, the number of iterations used for adaptation, and should not be used for inference. By default it is half of the iterations.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="4-bayesian-regression-1.html#cb3-1" aria-hidden="true" tabindex="-1"></a>model_bayes <span class="ot">&lt;-</span> <span class="fu">stan_glm</span>(medv<span class="sc">~</span>., <span class="at">data =</span> bost, <span class="at">seed =</span> <span class="dv">111</span>)</span></code></pre></div>
<pre><code>## 
## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 1).
## Chain 1: 
## Chain 1: Gradient evaluation took 8.3e-05 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.83 seconds.
## Chain 1: Adjust your expectations accordingly!
## Chain 1: 
## Chain 1: 
## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 1: 
## Chain 1:  Elapsed Time: 0.0778 seconds (Warm-up)
## Chain 1:                0.104278 seconds (Sampling)
## Chain 1:                0.182078 seconds (Total)
## Chain 1: 
## 
## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 2).
## Chain 2: 
## Chain 2: Gradient evaluation took 1.3e-05 seconds
## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.13 seconds.
## Chain 2: Adjust your expectations accordingly!
## Chain 2: 
## Chain 2: 
## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 2: 
## Chain 2:  Elapsed Time: 0.068216 seconds (Warm-up)
## Chain 2:                0.096927 seconds (Sampling)
## Chain 2:                0.165143 seconds (Total)
## Chain 2: 
## 
## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 3).
## Chain 3: 
## Chain 3: Gradient evaluation took 1e-05 seconds
## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds.
## Chain 3: Adjust your expectations accordingly!
## Chain 3: 
## Chain 3: 
## Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 3: 
## Chain 3:  Elapsed Time: 0.068952 seconds (Warm-up)
## Chain 3:                0.09789 seconds (Sampling)
## Chain 3:                0.166842 seconds (Total)
## Chain 3: 
## 
## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 4).
## Chain 4: 
## Chain 4: Gradient evaluation took 1.2e-05 seconds
## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.12 seconds.
## Chain 4: Adjust your expectations accordingly!
## Chain 4: 
## Chain 4: 
## Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 4: 
## Chain 4:  Elapsed Time: 0.074431 seconds (Warm-up)
## Chain 4:                0.098301 seconds (Sampling)
## Chain 4:                0.172732 seconds (Total)
## Chain 4:</code></pre>
<p>Print the model with <code>print</code> function from base R <span class="citation">[@R-base]</span>.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="4-bayesian-regression-1.html#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(model_bayes, <span class="at">digits =</span> <span class="dv">3</span>)</span></code></pre></div>
<pre><code>## stan_glm
##  family:       gaussian [identity]
##  formula:      medv ~ .
##  observations: 506
##  predictors:   4
## ------
##             Median MAD_SD
## (Intercept) 32.834  2.285
## age         -0.143  0.020
## dis         -0.258  0.257
## chas1        7.543  1.432
## 
## Auxiliary parameter(s):
##       Median MAD_SD
## sigma 8.324  0.260 
## 
## ------
## * For help interpreting the printed output see ?print.stanreg
## * For info on the priors used see ?prior_summary.stanreg</code></pre>
<p>The Median estimate is the median computed from the MCMC simulation, and <code>MAD_SD</code> is the median absolute deviation computed from the same simulation. To well understand how getting these outputs let’s plot the MCMC simulation of each predictor using <code>bayesplot</code></p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="4-bayesian-regression-1.html#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mcmc_dens</span>(model_bayes, <span class="at">pars =</span> <span class="fu">c</span>(<span class="st">&quot;age&quot;</span>)) <span class="sc">+</span></span>
<span id="cb7-2"><a href="4-bayesian-regression-1.html#cb7-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">vline_at</span>(<span class="sc">-</span><span class="fl">0.143</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="Bayes_Regression_files/figure-html/unnamed-chunk-6-1.png" width="672" />
As you see the point estimate of age falls on the median of this distribution (red line). The same thing is true for <code>dis</code> and <code>shas</code> predictors.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="4-bayesian-regression-1.html#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mcmc_dens</span>(model_bayes, <span class="at">pars=</span><span class="fu">c</span>(<span class="st">&quot;chas1&quot;</span>)) <span class="sc">+</span></span>
<span id="cb8-2"><a href="4-bayesian-regression-1.html#cb8-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">vline_at</span>(<span class="fl">7.496</span>, <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="Bayes_Regression_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="4-bayesian-regression-1.html#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mcmc_dens</span>(model_bayes, <span class="at">pars=</span><span class="fu">c</span>(<span class="st">&quot;dis&quot;</span>))<span class="sc">+</span></span>
<span id="cb9-2"><a href="4-bayesian-regression-1.html#cb9-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">vline_at</span>(<span class="sc">-</span><span class="fl">0.244</span>, <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="Bayes_Regression_files/figure-html/unnamed-chunk-8-1.png" width="672" />
Now how can we evaluate the model parameters? The answer is by analyzing the posteriors using some specific statistics. To get the full statistics provided by <code>bayestestR</code> package, we make use of the function <code>describe_posterior</code>.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="4-bayesian-regression-1.html#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">describe_posterior</span>(model_bayes)</span></code></pre></div>
<pre><code>## Possible multicollinearity between dis and age (r = 0.76). This might lead to inappropriate results. See &#39;Details&#39; in &#39;?rope&#39;.</code></pre>
<pre><code>## Summary of Posterior Distribution
## 
## Parameter   | Median |         95% CI |     pd |          ROPE | % in ROPE |  Rhat |     ESS
## --------------------------------------------------------------------------------------------
## (Intercept) |  32.83 | [28.43, 37.24] |   100% | [-0.92, 0.92] |        0% | 1.002 | 2029.00
## age         |  -0.14 | [-0.18, -0.10] |   100% | [-0.92, 0.92] |      100% | 1.001 | 2052.00
## dis         |  -0.26 | [-0.76,  0.26] | 81.92% | [-0.92, 0.92] |      100% | 1.002 | 2115.00
## chas1       |   7.54 | [ 4.74, 10.44] |   100% | [-0.92, 0.92] |        0% | 1.000 | 3744.00</code></pre>
<p>Possible multicollinearity between <code>dis</code> and <code>age</code> (r = 0.75). This might lead to inappropriate results. See ‘Details’ in <code>?rope</code>.</p>
<p>Before starting analyzing the table we should first understanding the above various statistics commonly used in Bayesian regression.</p>
<p><code>CI</code> : Credible Interval, it is used to quantify the uncertainty about the regression coefficients. There are tow methods to compute CI, the highest density interval HDI which is the default, and the Equal-tailed Interval ETI. with 89% probability (given the data) that a coefficient lies above the <code>CI_low</code> value and under <code>CI_high</code> value. This strightforward probabilistic interpretation is completely diffrent from the confidence interval used in classical linear regression where the coefficient fall inside this confidence interval (if we choose 95% of confidence) 95 times if we repeat the study 100 times.</p>
<p><code>pd</code> : Probability of Direction, which is the probability that the effect goes to the positive or to the negative direction, and it is considered as the best equivalent for the p-value.</p>
<p><code>ROPE_CI</code>: Region of Practical Equivalence, since bayes method deals with true probabilities , it does not make sense to compute the probability of getting the effect equals zero (the null hypothesis) as a point (probability of a point in continuous intervals equal zero). Thus, we define instead a small range around zero which can be considered practically the same as no effect (zero), this range therefore is called ROPE. By default (according to Cohen, 1988) The Rope is [-0.1,0.1] from the standardized coefficients.</p>
<p><code>Rhat</code>: scale reduction factor <span class="math inline">\(R^\)</span>, it is computed for each scalar quantity of interest, as the standard deviation of that quantity from all the chains included together, divided by the root mean square of the separate within-chain standard deviations. When this value is close to 1 we do not have any convergence problem with MCMC.</p>
<p><code>ESS</code> : effective sample size, it captures how many independent draws contain the same amount of information as the dependent sample obtained by the MCMC algorithm, the higher the ESS the better. The threshold used in practice is 400.
Alternatively, we can get the coefficient estimates (which are the medians by default) separately by using the package insight.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="4-bayesian-regression-1.html#cb13-1" aria-hidden="true" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">get_parameters</span>(model_bayes)</span></code></pre></div>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="4-bayesian-regression-1.html#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(purrr<span class="sc">::</span><span class="fu">map_dbl</span>(post,median),<span class="at">digits =</span> <span class="dv">3</span>)</span></code></pre></div>
<pre><code>## (Intercept)         age         dis       chas1 
##      32.834      -0.143      -0.258       7.543</code></pre>
<p>As we see the values are closer to each other due to the like normality of the distribution of the posteriors where all the central statistics (mean, median, mode) are closer to each other. Using the following plot to visualize the age coefficient using different statistics as follows</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="4-bayesian-regression-1.html#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mcmc_dens</span>(model_bayes, <span class="at">pars=</span><span class="fu">c</span>(<span class="st">&quot;age&quot;</span>))<span class="sc">+</span></span>
<span id="cb16-2"><a href="4-bayesian-regression-1.html#cb16-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">vline_at</span>(<span class="fu">median</span>(post<span class="sc">$</span>age), <span class="at">col=</span><span class="st">&quot;red&quot;</span>)<span class="sc">+</span></span>
<span id="cb16-3"><a href="4-bayesian-regression-1.html#cb16-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">vline_at</span>(<span class="fu">mean</span>(post<span class="sc">$</span>age), <span class="at">col=</span><span class="st">&quot;yellow&quot;</span>)<span class="sc">+</span></span>
<span id="cb16-4"><a href="4-bayesian-regression-1.html#cb16-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">vline_at</span>(<span class="fu">map_estimate</span>(post<span class="sc">$</span>age), <span class="at">col=</span><span class="st">&quot;green&quot;</span>)</span></code></pre></div>
<p><img src="Bayes_Regression_files/figure-html/unnamed-chunk-12-1.png" width="672" />
As expected they are approximately on top of each other.</p>
</div>
<p style="text-align: center;">
<a href="3-classical-linear-regression-model.html"><button class="btn btn-default">Previous</button></a>
<a href="5-bayesian-inferences.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
